{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando strides 2, 8 e 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch import nn\n",
    "from models import Decoder\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"Amostra ativações de um modelo ResNet do Pytorch e cria um decodificador.\"\"\"\n",
    "\n",
    "    def __init__(self, resnet_encoder, decoder_channels, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.resnet_encoder = resnet_encoder\n",
    "        encoder_channels_list = self.get_channels()\n",
    "        self.decoder = Decoder(encoder_channels_list, decoder_channels)\n",
    "        self.classification = nn.Conv2d(decoder_channels, num_classes, 3, padding=1)\n",
    "        \n",
    "    def get_features(self, x):\n",
    "            \n",
    "        features = []\n",
    "\n",
    "        # stride 2\n",
    "        re = self.resnet_encoder\n",
    "        x = re.conv1(x)\n",
    "        x = re.bn1(x)\n",
    "        x = re.relu(x)\n",
    "        features.append(x)\n",
    "\n",
    "        # stride 4\n",
    "        x = re.maxpool(x)\n",
    "        x = re.layer1(x)\n",
    "\n",
    "        # stride 8\n",
    "        x = re.layer2(x)\n",
    "        features.append(x)\n",
    "\n",
    "        # stride 16\n",
    "        x = re.layer3(x)\n",
    "\n",
    "        # stride 32\n",
    "        x = re.layer4(x)\n",
    "        features.append(x)\n",
    "\n",
    "        return features\n",
    "\n",
    "    def get_channels(self):\n",
    "\n",
    "        re = self.resnet_encoder\n",
    "        # Armazena se o modelo estava em modo treinamento\n",
    "        training = re.training\n",
    "        re.eval()\n",
    "\n",
    "        x = torch.zeros(1, 3, 224, 224)\n",
    "        with torch.no_grad():\n",
    "            features = self.get_features(x)\n",
    "        encoder_channels_list = [f.shape[1] for f in features]\n",
    "\n",
    "        # Volta para treinamento\n",
    "        if training:\n",
    "            re.train()\n",
    "\n",
    "        return encoder_channels_list\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in_shape = x.shape[-2:]\n",
    "        features = self.get_features(x)\n",
    "        x = self.decoder(features)\n",
    "\n",
    "        if x.shape[-2:]!=in_shape:\n",
    "            x = F.interpolate(x, size=in_shape, mode=\"nearest\")\n",
    "\n",
    "        # A camada de classificação poderia estar antes da interpolação, o que\n",
    "        # reduziria o custo computacional mas possivelmente levaria a segmentações\n",
    "        # menos detalhadas\n",
    "        x = self.classification(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "params = {\n",
    "    'bs_train':8,\n",
    "    'bs_valid':2,\n",
    "    'num_epochs':3,\n",
    "    'lr':0.01,\n",
    "    'weight_decay':1e-3,\n",
    "    'resize_size':384,  \n",
    "    'seed':0\n",
    "}\n",
    "\n",
    "encoder = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model = EncoderDecoder(encoder, decoder_channels=64, num_classes=2)\n",
    "ds_train, ds_valid, logger = train.train(model, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import dataset\n",
    "\n",
    "checkpoint = torch.load('../data/checkpoints/checkpoint.pt', map_location='cpu')\n",
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 3, figsize=(8,8))\n",
    "for idx in range(5):\n",
    "    img, target = ds_valid[idx]\n",
    "    with torch.no_grad():\n",
    "        scores = model(img.unsqueeze(0))\n",
    "    pred = torch.argmax(scores, dim=1)[0]\n",
    "    axs[idx,0].imshow(dataset.unormalize(img))\n",
    "    axs[idx,1].imshow(target, 'gray')\n",
    "    axs[idx,2].imshow(pred, 'gray')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint[\"logger\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ufscar-vc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
